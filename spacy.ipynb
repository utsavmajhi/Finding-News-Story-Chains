{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'European', 'JJ'),\n",
       " (u'authorities', 'NNS'),\n",
       " (u'fined', 'VBD'),\n",
       " (u'Google', 'NNP'),\n",
       " (u'a', 'DT'),\n",
       " (u'record', 'NN'),\n",
       " (u'$', '$'),\n",
       " (u'5.1', 'CD'),\n",
       " (u'billion', 'CD'),\n",
       " (u'on', 'IN'),\n",
       " (u'Wednesday', 'NNP'),\n",
       " (u'for', 'IN'),\n",
       " (u'abusing', 'VBG'),\n",
       " (u'its', 'PRP$'),\n",
       " (u'power', 'NN'),\n",
       " (u'in', 'IN'),\n",
       " (u'the', 'DT'),\n",
       " (u'mobile', 'JJ'),\n",
       " (u'phone', 'NN'),\n",
       " (u'market', 'NN'),\n",
       " (u'and', 'CC'),\n",
       " (u'ordered', 'VBD'),\n",
       " (u'the', 'DT'),\n",
       " (u'company', 'NN'),\n",
       " (u'to', 'TO'),\n",
       " (u'alter', 'VB'),\n",
       " (u'its', 'PRP$'),\n",
       " (u'practices', 'NNS')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  European/JJ\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  Google/NNP\n",
      "  (NP a/DT record/NN)\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  (NP power/NN)\n",
      "  in/IN\n",
      "  (NP the/DT mobile/JJ phone/NN)\n",
      "  (NP market/NN)\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (NP the/DT company/NN)\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS)\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'European', 'JJ', u'O'),\n",
      " (u'authorities', 'NNS', u'O'),\n",
      " (u'fined', 'VBD', u'O'),\n",
      " (u'Google', 'NNP', u'O'),\n",
      " (u'a', 'DT', u'B-NP'),\n",
      " (u'record', 'NN', u'I-NP'),\n",
      " (u'$', '$', u'O'),\n",
      " (u'5.1', 'CD', u'O'),\n",
      " (u'billion', 'CD', u'O'),\n",
      " (u'on', 'IN', u'O'),\n",
      " (u'Wednesday', 'NNP', u'O'),\n",
      " (u'for', 'IN', u'O'),\n",
      " (u'abusing', 'VBG', u'O'),\n",
      " (u'its', 'PRP$', u'O'),\n",
      " (u'power', 'NN', u'B-NP'),\n",
      " (u'in', 'IN', u'O'),\n",
      " (u'the', 'DT', u'B-NP'),\n",
      " (u'mobile', 'JJ', u'I-NP'),\n",
      " (u'phone', 'NN', u'I-NP'),\n",
      " (u'market', 'NN', u'B-NP'),\n",
      " (u'and', 'CC', u'O'),\n",
      " (u'ordered', 'VBD', u'O'),\n",
      " (u'the', 'DT', u'B-NP'),\n",
      " (u'company', 'NN', u'I-NP'),\n",
      " (u'to', 'TO', u'O'),\n",
      " (u'alter', 'VB', u'O'),\n",
      " (u'its', 'PRP$', u'O'),\n",
      " (u'practices', 'NNS', u'O')]\n",
      "(S\n",
      "  (GPE European/JJ)\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  (PERSON Google/NNP)\n",
      "  a/DT\n",
      "  record/NN\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  power/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  mobile/JJ\n",
      "  phone/NN\n",
      "  market/NN\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  the/DT\n",
      "  company/NN\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import conll2000\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "\n",
    "pprint(iob_tagged)\n",
    "ne_tree = ne_chunk(pos_tag(word_tokenize(ex)))\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from __future__ import unicode_literals\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'European', u'NORP'),\n",
      " (u'Google', u'ORG'),\n",
      " (u'$5.1 billion', u'MONEY'),\n",
      " (u'Wednesday', u'DATE')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
    "pprint([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(European, u'B', u'NORP'),\n",
      " (authorities, u'O', u''),\n",
      " (fined, u'O', u''),\n",
      " (Google, u'B', u'ORG'),\n",
      " (a, u'O', u''),\n",
      " (record, u'O', u''),\n",
      " ($, u'B', u'MONEY'),\n",
      " (5.1, u'I', u'MONEY'),\n",
      " (billion, u'I', u'MONEY'),\n",
      " (on, u'O', u''),\n",
      " (Wednesday, u'B', u'DATE'),\n",
      " (for, u'O', u''),\n",
      " (abusing, u'O', u''),\n",
      " (its, u'O', u''),\n",
      " (power, u'O', u''),\n",
      " (in, u'O', u''),\n",
      " (the, u'O', u''),\n",
      " (mobile, u'O', u''),\n",
      " (phone, u'O', u''),\n",
      " (market, u'O', u''),\n",
      " (and, u'O', u''),\n",
      " (ordered, u'O', u''),\n",
      " (the, u'O', u''),\n",
      " (company, u'O', u''),\n",
      " (to, u'O', u''),\n",
      " (alter, u'O', u''),\n",
      " (its, u'O', u''),\n",
      " (practices, u'O', u'')]\n"
     ]
    }
   ],
   "source": [
    "pprint([(X, X.ent_iob_, X.ent_type_) for X in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "     \n",
    "def url_to_string(url):\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    for script in soup([\"script\", \"style\", 'aside']):\n",
    "        script.extract()\n",
    "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))\n",
    "ny_bb = url_to_string('https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\n",
    "article = nlp(ny_bb)\n",
    "len(article.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'CARDINAL': 4,\n",
       "         u'DATE': 31,\n",
       "         u'EVENT': 1,\n",
       "         u'GPE': 29,\n",
       "         u'NORP': 5,\n",
       "         u'ORDINAL': 1,\n",
       "         u'ORG': 22,\n",
       "         u'PERSON': 81})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [x.label_ for x in article.ents]\n",
    "Counter(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Strzok', 32), (u'F.B.I.', 17), (u'Trump', 10)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [x.text for x in article.ents]\n",
    "Counter(items).most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firing Mr. Strzok, however, removes a favorite target of Mr. Trump from the ranks of the F.B.I. and gives Mr. Bowdich and the F.B.I. director, Christopher A. Wray, a chance to move beyond the president’s ire.\n"
     ]
    }
   ],
   "source": [
    "sentences = [x for x in article.sents]\n",
    "print(sentences[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected unicode, got str)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-47b5c1f7df84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjupyter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\utsav\\Anaconda3\\envs\\python2\\lib\\site-packages\\spacy\\language.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable)\u001b[0m\n\u001b[0;32m    344\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[0;32m    345\u001b[0m                                                 max_length=self.max_length))\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\utsav\\Anaconda3\\envs\\python2\\lib\\site-packages\\spacy\\language.pyc\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected unicode, got str)"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "displacy.render(nlp(str(sentences[20])), jupyter=True, style='ent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
